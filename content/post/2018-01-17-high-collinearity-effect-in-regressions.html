---
title: High Collinearity Effect in Regressions
author: Giuliano Sposito
date: '2018-01-17'
categories:
  - data science
tags:
  - rstat
  - feature engineering
  - evalutation
draft: true
slug: high-collinearity-effect-in-regressions
disqusIdentifier: high-collinearity-effect-in-regressions
---



<p>Collinearity refers to the situation in which two or more predictor variables collinearity are closely related to one another. The presence of collinearity can pose problems in the regression context, since it can be difficult to separate out the individual effects of collinear variables on the response.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>This <a href="http://rmarkdown.rstudio.com/r_notebooks.html">R Notebook</a> seeks to ilustrate some of the difficulties that can be result from a collinearity.</p>
<div id="collinearity" class="section level2">
<h2>Collinearity</h2>
<p>The concept of collinearity is illustrated in Figure below using the <code>Credit</code> data set in the <code>ISLR Package</code>. In the left-hand panel of Figure the two predictors <code>limit</code> and <code>age</code> appear to have no obvious relationship. In contrast, in the right-hand panel the predictors <code>limit</code> and <code>rating</code> are very highly correlated with each other, and we say that they are collinear.</p>
<pre class="r"><code># setup
library(ISLR)
library(tidyverse)
library(ggplot2)
library(grid)
library(gridExtra)


ggplot(Credit, aes(x=Limit, y=Age)) +
  geom_point() +
  theme_bw() -&gt; p1

ggplot(Credit, aes(x=Limit, y=Rating)) +
  geom_point() +
  theme_bw() -&gt; p2

marrangeGrob(list(p1,p2), nrow=1, ncol=2)</code></pre>
<p><img src="/post/2018-01-17-high-collinearity-effect-in-regressions_files/figure-html/collinearity-1.png" width="672" /></p>
</div>
<div id="effect-on-a-model" class="section level2">
<h2>Effect on a Model</h2>
<p>Let’s fit two models using these pair of features (<code>age</code> x <code>limit</code> and <code>Rating</code> x <code>Limit</code>) to predict the <code>Balance</code> outcome and see what happen with the model performances</p>
<pre class="r"><code># balance in function of Age and Limit
fit_axl &lt;- lm(Balance~Age+Limit, Credit)
summary(fit_axl)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Age + Limit, data = Credit)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -696.84 -150.78  -13.01  126.68  755.56 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.734e+02  4.383e+01  -3.957 9.01e-05 ***
## Age         -2.291e+00  6.725e-01  -3.407 0.000723 ***
## Limit        1.734e-01  5.026e-03  34.496  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 230.5 on 397 degrees of freedom
## Multiple R-squared:  0.7498, Adjusted R-squared:  0.7486 
## F-statistic:   595 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The first is a regression of <code>balance</code> on <code>age</code> and <code>limit</code>, here both <code>age</code> and <code>limit</code> are <strong>highly significant with very small <em>p-values</em></strong>.</p>
<pre class="r"><code># balance in function of Rating and Limit
fit_rxl &lt;- lm(Balance~Rating+Limit, Credit)
summary(fit_rxl)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Balance ~ Rating + Limit, data = Credit)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -707.8 -135.9   -9.5  124.0  817.6 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -377.53680   45.25418  -8.343 1.21e-15 ***
## Rating         2.20167    0.95229   2.312   0.0213 *  
## Limit          0.02451    0.06383   0.384   0.7012    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 232.3 on 397 degrees of freedom
## Multiple R-squared:  0.7459, Adjusted R-squared:  0.7447 
## F-statistic: 582.8 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In the second, the collinearity between <code>limit</code> and <code>rating</code> has caused the standard error for the limit coefficient estimate to increase by a factor of 12 and the <em>p-value</em> to increase to 0.701. In other words, <strong>the importance of the limit variable has been masked due to the presence of collinearity</strong>.</p>
<p><em>Collinearity reduces the accuracy of the estimates of the regression coefficients</em>, it causes the standard error for ??^j to grow. Recall that the <code>t-statistic</code> for each predictor is calculated by dividing <span class="math inline">\(\hat{??}_j\)</span> by its standard error. Consequently, collinearity results in a decline in the <code>t-statistic</code>. As a result, in the presence of collinearity, we may fail to reject <code>H0 : ??j = 0</code>. This means that the power of the hypothesis test-the probability of correctly power detecting a non-zero coefficient-is reduced by collinearity.</p>
</div>
<div id="cost-surface" class="section level2">
<h2>Cost Surface</h2>
<p>Why the collinearity reduces the accuracy of the regression coefficients? What is the effect of it in the fitting model? To visualize the effect lets plot the <code>Cost Function</code> surface (RSS) in the space of the coefficents.</p>
<pre class="r"><code>coef(fit_axl)</code></pre>
<pre><code>## (Intercept)         Age       Limit 
## -173.410901   -2.291486    0.173365</code></pre>
<pre class="r"><code>cfit &lt;- confint(fit_axl)

int &lt;- coef(fit_axl)[1]
b1 &lt;- seq(cfit[2,1], cfit[2,2], abs((cfit[2,1]-cfit[2,2])/100) ) # age
b2 &lt;- seq(cfit[3,1], cfit[3,2], abs((cfit[3,1]-cfit[3,2])/100) ) # limit
coefs &lt;- expand.grid(b1,b2)


rss_grid &lt;- map(coefs,function(coef,dt=Credit,inter=int){
  y_hat &lt;- inter + coef[[1]] * Credit$Age + coef[[2]] * Credit$Limit
  sum((Credit$Balance - y_hat)^2)
}) </code></pre>
<div id="references" class="section level3">
<h3>References</h3>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Introduction to Statistical Learning in R<a href="#fnref1">↩</a></p></li>
</ol>
</div>
