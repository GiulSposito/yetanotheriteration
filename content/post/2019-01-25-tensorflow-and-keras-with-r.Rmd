---
title: "Tensorflow and Keras with R"
author: "Giuliano Sposito"
date: '2019-01-25'
coverImage: /images/lenet_keras_cover.jpg
metaAlignment: center
slug: tensorflow-and-keras-with-r
categories:
  - data science
tags:
- machine learning
- keras
- tensorflow
- data analysis
- en-US
- mnist
- neural network
thumbnailImage: images/lenet_keras_tn.jpg
thumbnailImagePosition: left
---

I'll start series of post about [Keras](https://keras.io/), a high-level [neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network) API developed with a focus on enabling fast experimentation, running on top of [TensorFlow](https://www.tensorflow.org), but using its [R interface](https://keras.rstudio.com/). To start, we'll review our [LeNet implemantation with MXNET](https://yetanotheriteration.netlify.com/2018/01/implementing-lenet-with-mxnet-in-r/) for [MNIST problem](http://yann.lecun.com/exdb/mnist/), a traditional "[Hello World](https://en.wikipedia.org/wiki/%22Hello,_World!%22_program)" in the Neural Network world.


<!--more-->


## About Keras in R

[Keras](https://keras.io/) is an API for building neural networks written in [Python](https://www.python.org/) capable of running on top of [Tensorflow](https://www.tensorflow.org), [CNTK](https://github.com/Microsoft/cntk), or [Theano](https://github.com/Theano/Theano). It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.

We'll use a [R implementation](https://keras.rstudio.com/) of Keras, that communicates with the Python environment using the [Reticulate Package](https://rstudio.github.io/reticulate/) to build and run neural networks on Tensorflow backend.


## Instruction for Setup

It's necessary install an Python and Tensorflow environments in the machine, also, to make Tensorflow run over [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit) you will need install nvidia's [CUDA Toolkit](https://developer.nvidia.com/cuda-zone) and [cuDNN libraries](https://developer.nvidia.com/cudnn) In my experience this is very easy and cheap using a Ubuntu [preemptible](https://cloud.google.com/compute/docs/instances/preemptible) [Google Compute Engine](https://cloud.google.com/) instance. You can follow the install instructions here: https://tensorflow.rstudio.com/tools/local_gpu.html

```{r loadLib, echo=FALSE}
# loading keras lib
library(keras)
```
## Databaset and Tensors

The Keras package already provides a set of datasets and pre-trained neural networksto serve as a learning base, the MNIST dataset is one of them, let's load it.


```{r loadData, cache=TRUE}

# loading keras lib
library(keras)

# loading and preparing dataset
mnist <- dataset_mnist() 

# separate the datasets
x.train <- mnist$train$x
lbl.train <- mnist$train$y
x.test <-  mnist$test$x
lbl.test <-  mnist$test$y

# let's see what we have
str(x.train)
str(lbl.train)
summary(x.train)

```


The first time you invoke `dataset_mnist ()` the data will be downloaded, we can see that we get a three-dimensional array, in the first dimension we have the index of the case, and for each one of them we have a matrix of 28x28 that corresponds the image of a number.

To use with "tensorflow/keras" it is necessary to convert the matrix to a "tensor" (generalization of a vector), in this case we have to convert to an array of n x 28 x 28 x 1 digits, where "n", in the first dimension is the "case" and the "1" (last dimension) is only "one channel" for each pixel of the image. As the channel will be the input signal to the neurons, it is advisable to normalize it, since the dataset is integers ranging from 0 to 255, we will simple normalize it to a range of 0.0 to 1.0.

```{r reshapeDataset, cache=TRUE}

# Redefine dimension of train/test inputs to 2D "tensors" (28x28x1)
x.train <- array_reshape(x.train, c(nrow(x.train), 28,28,1))
x.test  <- array_reshape(x.test,  c(nrow(x.test),  28,28,1))

# normalize values to be between 0.0 - 1.0
x.train <- x.train/255
x.test  <- x.test/255

str(x.train)
summary(x.train)

```


In addition, it is necessary to convert the classification label using [one-hot encoding](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/), since we neural network classifies the image into one of the ten possibilities (from 0 to 9).


```{r oneHotEncoding, cache=TRUE}

# one hot encoding
y.train <- to_categorical(lbl.train,10)
y.test  <- to_categorical(lbl.test,10)

str(y.train)

```

Let's see some numbers in the dataset.

```{r viewCases, cache=TRUE}

# plot one case
show_digit <- function(tensor, col=gray(12:1/12), ...) {
  tensor %>% 
    apply(., 2, rev) %>%      # reorient to make a 90 cw rotation
    t() %>%                   # reorient to make a 90 cw rotation
    image(col=col, axes=F, asp=1, ...)       # plot matrix as image
}

# check some data
par(mfrow=c(1,5), mar=c(0.1,0.1,0.1,0.1))
for(i in 1:5) show_digit(x.train[i,,,])
print(lbl.train[1:5])

```


## LeNet Archtecture

I'll use one of the LeNet architecture for the neural network, based in two sets of Convolutional filters and poolings and two fully connected layers, as show bellow

![LetNet](https://www.pyimagesearch.com/wp-content/uploads/2016/06/lenet_architecture.png)

We'll build a sequential model, adding layer by layer in the network.

```{r buildModel, cache=TRUE}
# build lenet
keras_model_sequential() %>% 
  layer_conv_2d(input_shape=c(28,28,1), filters=20, kernel_size = c(5,5), activation = "tanh") %>% 
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>% 
  layer_conv_2d(filters = 50, kernel_size = c(5,5), activation="tanh" ) %>% 
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2) ) %>% 
  layer_dropout(rate=0.3) %>% 
  layer_flatten() %>% 
  layer_dense(units = 500, activation = "tanh" ) %>% 
  layer_dropout(rate=0.3) %>% 
  layer_dense(units=10, activation = "softmax") -> model

# lets look the summary
summary(model)
```

In keras you have to define your network and have to compile it, this function defines:
- Loss function
- Optimizer/Learning Rate
- Evalutation Metrics

```{r compileModel, cache=TRUE, eval=FALSE}
# keras compile
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)

```

## Train and Evaluate

Finnaly, your network is ready to train, let's to it with `fit()` function.

```{r trainNetwork, eval=FALSE}

# train the model and store the evolution history
history <- model %>% fit(
  x.train, y.train, epochs=30, batch_size=128,
  validation_split=0.3
)

# plot the network evolution
plot(history)
```

```{r loadNetwork, echo=FALSE, warning=FALSE, message=FALSE}
model <- load_model_hdf5("./models/mnist_lenet.hdf5")
history <- readRDS("./models/mnist_lenet_history.rds")
plot(history)
```

Let's see how good the fitted model are applying the model in the test set

```{r evalModel, cache=TRUE}

# evaluating the model
evaluate(model, x.test, y.test)

```

As you see, it's an impressive 99% of accuracy.

## Visualizing the Activation Layers

As we did in the [mxnet post](https://yetanotheriteration.netlify.com/2018/01/implementing-lenet-with-mxnet-in-r/), let's see how the internal layers react to a input data visualizing the neuron's activation pattern:

```{r activations, cache=TRUE}
# Extracts the outputs of the top 8 layers:
layer_outputs <- lapply(model$layers[1:8], function(layer) layer$output)

# Creates a model that will return these outputs, given the model input:
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)

# choose a case
a_digit <- array_reshape(x.train[45,,,], c(1,28,28,1))

# Returns a list of five arrays: one array per layer activation
activations <- activation_model %>% predict(a_digit)

# plot a tensor channel
plot_channel <- function(channel) {
  rotate <- function(x) t(apply(x, 2, rev))
  image(rotate(channel), axes = FALSE, asp = 1)
}

# plot the channels of a layout ouput (activation)
plotActivations <- function(.activations, .index){
  layer_inpected <- .activations[[.index]]
  par(mfrow=c(dim(layer_inpected)[4]/5,5), mar=c(0.1,0.1,0.1,0.1))
  for(i in 1:dim(layer_inpected)[4]) plot_channel(layer_inpected[1,,,i])
}

# look the 2D layers activations
plotActivations(activations, 1) # conv2D - tanh
plotActivations(activations, 2) # max pooling
plotActivations(activations, 3) # conv2D - tanh
plotActivations(activations, 4) # max pooling

```

