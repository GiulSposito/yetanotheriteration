<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Evalutation on Yet Another Iteration</title>
    <link>https://yetanotheriteration.netlify.com/tags/evalutation/</link>
    <description>Recent content in Evalutation on Yet Another Iteration</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://yetanotheriteration.netlify.com/tags/evalutation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>kNN Analysis on MNIST with 97% accuracy</title>
      <link>https://yetanotheriteration.netlify.com/2018/01/knn-analysis-on-mnist-with-97-accuracy/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yetanotheriteration.netlify.com/2018/01/knn-analysis-on-mnist-with-97-accuracy/</guid>
      <description>Usually Yann LeCun’s MNIST database is used to explore Artificial Neural Network architectures for image recognition problem.
In the last post the use of a ANN (LeNet architecture) implemented using mxnet to resolve this classification problem.
But in this post, we’ll see that the MNIST problem isn’t a difficult one, only resolved by ANNs, analyzing the data set we can see that is possible, with a high degree of precision, resolving this classification problem with a simple k-nearest neighbors algorithm.</description>
    </item>
    
    <item>
      <title>High Collinearity Effect in Regressions</title>
      <link>https://yetanotheriteration.netlify.com/2018/01/high-collinearity-effect-in-regressions/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yetanotheriteration.netlify.com/2018/01/high-collinearity-effect-in-regressions/</guid>
      <description>Collinearity refers to the situation in which two or more predictor variables collinearity are closely related to one another. The presence of collinearity can pose problems in the regression context, since it can be difficult to separate out the individual effects of collinear variables on the response.
This R Notebook seeks to ilustrate some of the difficulties that can be result from a collinearity.</description>
    </item>
    
    <item>
      <title>Assessing Model Accuracy (Linear Models)</title>
      <link>https://yetanotheriteration.netlify.com/2018/01/assessing-model-accuracy-linear-modelsrmd/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yetanotheriteration.netlify.com/2018/01/assessing-model-accuracy-linear-modelsrmd/</guid>
      <description>This post talks about the use of Mean Squared Error (MSE) against the flexibility of a function fitted as a technique to assess the model accuracy in a specific problem as describe in the An Introduction to Statistical Learning in R book.
Measure the quality of fit (regression problems)In order to evaluate the performance of a statistical learning method on a given data set, we need some way to measure how well its predictions actually match the observed data.</description>
    </item>
    
  </channel>
</rss>